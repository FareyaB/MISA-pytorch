{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array 0 final loss: 272.3525\n",
      "/data/users2/dkhosravinezhad1/MISA-pytorch/slurm_log/output6187170-0.out does not contain a 75th epoch\n",
      "array 0 MATLAB loss epoch: 400\n",
      "array 1 final loss: 170.5219\n",
      "/data/users2/dkhosravinezhad1/MISA-pytorch/slurm_log/output6187170-1.out does not contain a 75th epoch\n",
      "array 1 MATLAB loss epoch: 8\n",
      "array 2 final loss: 171.2422\n",
      "/data/users2/dkhosravinezhad1/MISA-pytorch/slurm_log/output6187170-2.out does not contain a 75th epoch\n",
      "array 2 MATLAB loss epoch: 2\n",
      "array 3 final loss: 230.3706\n",
      "/data/users2/dkhosravinezhad1/MISA-pytorch/slurm_log/output6187170-3.out does not contain a 75th epoch\n",
      "array 3 MATLAB loss epoch: 400\n",
      "array 4 final loss: 171.3442\n",
      "/data/users2/dkhosravinezhad1/MISA-pytorch/slurm_log/output6187170-4.out does not contain a 75th epoch\n",
      "array 4 MATLAB loss epoch: 3\n",
      "array 5 final loss: 199.2056\n",
      "/data/users2/dkhosravinezhad1/MISA-pytorch/slurm_log/output6187170-5.out does not contain a 75th epoch\n",
      "array 5 MATLAB loss epoch: 400\n",
      "array 6 final loss: 171.1833\n",
      "/data/users2/dkhosravinezhad1/MISA-pytorch/slurm_log/output6187170-6.out does not contain a 75th epoch\n",
      "array 6 MATLAB loss epoch: 3\n",
      "array 7 final loss: 273.5770\n",
      "/data/users2/dkhosravinezhad1/MISA-pytorch/slurm_log/output6187170-7.out does not contain a 75th epoch\n",
      "array 7 MATLAB loss epoch: 400\n",
      "array 8 final loss: 172.4877\n",
      "/data/users2/dkhosravinezhad1/MISA-pytorch/slurm_log/output6187170-8.out does not contain a 75th epoch\n",
      "array 8 MATLAB loss epoch: 2\n",
      "array 9 final loss: 188.5131\n",
      "/data/users2/dkhosravinezhad1/MISA-pytorch/slurm_log/output6187170-9.out does not contain a 75th epoch\n",
      "array 9 MATLAB loss epoch: 400\n",
      "array 10 final loss: 204.6849\n",
      "array 10 75th loss: 206.7620\n",
      "array 0 MATLAB loss epoch: 63\n",
      "array 11 final loss: 174.4696\n",
      "array 11 75th loss: 173.4034\n",
      "array 1 MATLAB loss epoch: 36\n",
      "array 12 final loss: 171.2244\n",
      "array 12 75th loss: 168.8826\n",
      "array 2 MATLAB loss epoch: 8\n",
      "array 13 final loss: 170.6767\n",
      "array 13 75th loss: 169.5737\n",
      "array 3 MATLAB loss epoch: 7\n",
      "array 14 final loss: 201.3573\n",
      "array 14 75th loss: 211.2994\n",
      "array 4 MATLAB loss epoch: 400\n",
      "array 15 final loss: 170.5393\n",
      "array 15 75th loss: 170.1800\n",
      "array 5 MATLAB loss epoch: 11\n",
      "array 16 final loss: 170.4237\n",
      "array 16 75th loss: 170.2190\n",
      "array 6 MATLAB loss epoch: 5\n",
      "array 17 final loss: 170.2624\n",
      "array 17 75th loss: 170.6572\n",
      "array 7 MATLAB loss epoch: 4\n",
      "array 18 final loss: 167.5733\n",
      "array 18 75th loss: 170.8656\n",
      "array 8 MATLAB loss epoch: 9\n",
      "array 19 final loss: 176.2536\n",
      "array 19 75th loss: 177.9590\n",
      "array 9 MATLAB loss epoch: 400\n",
      "array 0 learning rate = 1.5485873313524224e-05\n",
      "array 0 epochs = 10\n",
      "array 0 batch size = 624\n",
      "array 1 learning rate = 0.002423107963339815\n",
      "array 1 epochs = 10\n",
      "array 1 batch size = 329\n",
      "array 2 learning rate = 0.010178534844817913\n",
      "array 2 epochs = 10\n",
      "array 2 batch size = 68\n",
      "array 3 learning rate = 0.00030267426339163756\n",
      "array 3 epochs = 10\n",
      "array 3 batch size = 996\n",
      "array 4 learning rate = 0.009239039877517135\n",
      "array 4 epochs = 10\n",
      "array 4 batch size = 183\n",
      "array 5 learning rate = 0.08105255280156817\n",
      "array 5 epochs = 10\n",
      "array 5 batch size = 25\n",
      "array 6 learning rate = 0.005119575903806145\n",
      "array 6 epochs = 10\n",
      "array 6 batch size = 127\n",
      "array 7 learning rate = 1.2444936348116345e-05\n",
      "array 7 epochs = 10\n",
      "array 7 batch size = 102\n",
      "array 8 learning rate = 0.004610841566767592\n",
      "array 8 epochs = 10\n",
      "array 8 batch size = 25\n",
      "array 9 learning rate = 0.00026268235607603463\n",
      "array 9 epochs = 10\n",
      "array 9 batch size = 285\n",
      "array 10 learning rate = 1.546058927618459e-05\n",
      "array 10 epochs = 80\n",
      "array 10 batch size = 247\n",
      "array 11 learning rate = 0.022399887666801968\n",
      "array 11 epochs = 80\n",
      "array 11 batch size = 107\n",
      "array 12 learning rate = 0.0003761912835308907\n",
      "array 12 epochs = 80\n",
      "array 12 batch size = 48\n",
      "array 13 learning rate = 0.0005525104065016169\n",
      "array 13 epochs = 80\n",
      "array 13 batch size = 49\n",
      "array 14 learning rate = 1.1899011269617424e-05\n",
      "array 14 epochs = 80\n",
      "array 14 batch size = 175\n",
      "array 15 learning rate = 0.0003602360488578598\n",
      "array 15 epochs = 80\n",
      "array 15 batch size = 87\n",
      "array 16 learning rate = 0.01142744799302142\n",
      "array 16 epochs = 80\n",
      "array 16 batch size = 461\n",
      "array 17 learning rate = 0.0013538685548585775\n",
      "array 17 epochs = 80\n",
      "array 17 batch size = 490\n",
      "array 18 learning rate = 0.0001997785127635794\n",
      "array 18 epochs = 80\n",
      "array 18 batch size = 43\n",
      "array 19 learning rate = 0.06262223564802699\n",
      "array 19 epochs = 80\n",
      "array 19 batch size = 156\n",
      "learning rate list:[1.5485873313524224e-05, 0.002423107963339815, 0.010178534844817913, 0.00030267426339163756, 0.009239039877517135, 0.08105255280156817, 0.005119575903806145, 1.2444936348116345e-05, 0.004610841566767592, 0.00026268235607603463, 1.546058927618459e-05, 0.022399887666801968, 0.0003761912835308907, 0.0005525104065016169, 1.1899011269617424e-05, 0.0003602360488578598, 0.01142744799302142, 0.0013538685548585775, 0.0001997785127635794, 0.06262223564802699]\n",
      "epochs list: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80]\n",
      "batch size list: [624, 329, 68, 996, 183, 25, 127, 102, 25, 285, 247, 107, 48, 49, 175, 87, 461, 490, 43, 156]\n",
      "final loss list: ['272.3525', '170.5219', '171.2422', '230.3706', '171.3442', '199.2056', '171.1833', '273.5770', '172.4877', '188.5131', '204.6849', '174.4696', '171.2244', '170.6767', '201.3573', '170.5393', '170.4237', '170.2624', '167.5733', '176.2536']\n",
      "75th loss list: [None, None, None, None, None, None, None, None, None, None, '206.7620', '173.4034', '168.8826', '169.5737', '211.2994', '170.1800', '170.2190', '170.6572', '170.8656', '177.9590']\n",
      "MATLAB loss epoch list: [400, 8, 2, 400, 3, 400, 3, 400, 2, 400, 63, 36, 8, 7, 400, 11, 5, 4, 9, 400]\n",
      "learning rate list length: 20\n",
      "epochs list length: 20\n",
      "batch size list length: 20\n",
      "final loss list length: 20\n",
      "75th loss list length: 20\n",
      "MATLAB loss epoch list length: 20\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "from os.path import exists\n",
    "import fnmatch\n",
    "import natsort\n",
    "from re import search\n",
    "\n",
    "filepath = '/data/users2/dkhosravinezhad1/MISA-pytorch/run'\n",
    "loss_filepath = '/data/users2/dkhosravinezhad1/MISA-pytorch/slurm_log'\n",
    "array_number = len(os.listdir(filepath)[2:])\n",
    "slurm_length = int(len(os.listdir(loss_filepath))/2)\n",
    "slurm_filename = []\n",
    "for i in os.listdir(loss_filepath):\n",
    "  if fnmatch.fnmatch(i, 'output*'):\n",
    "    slurm_filename.append(i)\n",
    "slurm_filename = natsort.natsorted(slurm_filename)\n",
    "slurm_final_loss = [-1]\n",
    "filename = 'res_sim-siva.p'# input(\"Insert file directory here: \")\n",
    "loss = []\n",
    "seventy_fifth_loss = []\n",
    "filetype = filename[-2:]\n",
    "lr = []\n",
    "epochs = []\n",
    "batch_size = []\n",
    "epoch = []\n",
    "h = 0\n",
    "for i in range(slurm_length):\n",
    "  slurm_full = os.path.join(loss_filepath,slurm_filename[i])\n",
    "  output_exists = exists(slurm_full)\n",
    "  if os.stat(slurm_full).st_size != 0:\n",
    "    if i < 10:\n",
    "      with open(slurm_full, 'r') as lost:\n",
    "        loss_line = lost.readlines()[-2]\n",
    "        print(\"array \" + (slurm_full[-19:])[-5] + \" final loss: \" + loss_line[-27:-19])\n",
    "        loss.append(loss_line[-27:-19])\n",
    "        lost.seek(0)\n",
    "        seventy = len(lost.readlines())\n",
    "        if seventy >= 78:\n",
    "          with open(slurm_full, 'r') as lost:\n",
    "            seven_five = lost.readlines()[78]\n",
    "            print(\"array \" + (slurm_full[-20:])[-5] + \" 75th loss: \" + seven_five[-27:-19])\n",
    "            seventy_fifth_loss.append(seven_five[-27:-19])\n",
    "            lost.seek(0)\n",
    "        else:\n",
    "          print(slurm_full + \" does not contain a 75th epoch\")\n",
    "          seventy_fifth_loss.append(None)\n",
    "      with open(slurm_full, 'r') as lost:\n",
    "        epoch_iterations = lost.readlines()[4:-1]\n",
    "        epoch_list = []\n",
    "        for i in epoch_iterations:\n",
    "            epoch_list.append(i[-27:-19])\n",
    "        for i, l in enumerate(epoch_list):\n",
    "          if search('170', l):\n",
    "            epoch.append(i+1)\n",
    "            print(\"array \" + (slurm_full[-20:])[-5] + \" MATLAB loss epoch: \" + str(i+1))\n",
    "            break\n",
    "          elif search('169', l):\n",
    "            epoch.append(i+1)\n",
    "            print(\"array \" + (slurm_full[-20:])[-5] + \" MATLAB loss epoch: \" + str(i+1))\n",
    "            break\n",
    "        else:\n",
    "          epoch.append(400)\n",
    "          print(\"array \" + (slurm_full[-20:])[-5] + \" MATLAB loss epoch: 400\")\n",
    "    elif i < 99:\n",
    "      with open(slurm_full, 'r') as lost:\n",
    "        loss_line = lost.readlines()[-2]\n",
    "        print(\"array \" + (slurm_full[-20:])[-6:-4] + \" final loss: \" + loss_line[-27:-19])\n",
    "        loss.append(loss_line[-27:-19])\n",
    "        lost.seek(0)\n",
    "        seventy = len(lost.readlines())\n",
    "        if seventy >= 78:\n",
    "          with open(slurm_full, 'r') as lost:\n",
    "            seven_five = lost.readlines()[78]\n",
    "            print(\"array \" + (slurm_full[-20:])[-6:-4] + \" 75th loss: \" + seven_five[-27:-19])\n",
    "            seventy_fifth_loss.append(seven_five[-27:-19])\n",
    "            lost.seek(0)\n",
    "        else:\n",
    "          print(slurm_full + \" does not contain a 75th epoch\")\n",
    "          seventy_fifth_loss.append(None)\n",
    "      with open(slurm_full, 'r') as lost:\n",
    "        epoch_iterations = lost.readlines()[4:-1]\n",
    "        epoch_list = []\n",
    "        for i in epoch_iterations:\n",
    "            epoch_list.append(i[-27:-19])\n",
    "        for i, l in enumerate(epoch_list):\n",
    "          if search('170', l):\n",
    "            epoch.append(i)\n",
    "            print(\"array \" + (slurm_full[-20:])[-5] + \" MATLAB loss epoch: \" + str(i))\n",
    "            break\n",
    "          elif search('169', l):\n",
    "            epoch.append(i)\n",
    "            print(\"array \" + (slurm_full[-20:])[-5] + \" MATLAB loss epoch: \" + str(i))\n",
    "            break\n",
    "        else:\n",
    "          epoch.append(400)\n",
    "          print(\"array \" + (slurm_full[-20:])[-5] + \" MATLAB loss epoch: 400\")\n",
    "    else:\n",
    "      with open(slurm_full, 'r') as lost:\n",
    "        loss_line = lost.readlines()[-2]\n",
    "        print(\"array \" + (slurm_full[-21:])[-6:-3] + \" final loss: \" + loss_line[-27:-19])\n",
    "        loss.append(loss_line[-27:-19])\n",
    "        lost.seek(0)\n",
    "        seventy = len(lost.readlines())\n",
    "        if seventy >= 78:\n",
    "          with open(slurm_full, 'r') as lost:\n",
    "            seven_five = lost.readlines()[78]\n",
    "            print(\"array \" + (slurm_full[-20:])[-6:-3] + \" 75th loss: \" + seven_five[-27:-19])\n",
    "            seventy_fifth_loss.append(seven_five[-27:-19])\n",
    "            lost.seek(0)\n",
    "        else:\n",
    "          print(slurm_full + \" does not contain a 75th epoch\")\n",
    "          seventy_fifth_loss.append(None)\n",
    "      with open(slurm_full, 'r') as lost:\n",
    "        epoch_iterations = lost.readlines()[4:-1]\n",
    "        epoch_list = []\n",
    "        for i in epoch_iterations:\n",
    "            epoch_list.append(i[-27:-19])\n",
    "        for i, l in enumerate(epoch_list):\n",
    "          if search('170', l):\n",
    "            epoch.append(i)\n",
    "            print(\"array \" + (slurm_full[-20:])[-5] + \" MATLAB loss epoch: \" + str(i))\n",
    "            break\n",
    "          elif search('169', l):\n",
    "            epoch.append(i)\n",
    "            print(\"array \" + (slurm_full[-20:])[-5] + \" MATLAB loss epoch: \" + str(i))\n",
    "            break\n",
    "          else:\n",
    "            epoch.append(400)\n",
    "            print(\"array \" + (slurm_full[-20:])[-5] + \" MATLAB loss epoch: 400\")\n",
    "  else:\n",
    "    print(slurm_full + \" has no contents. Check error file for problem!\")\n",
    "\n",
    "for i in range(array_number):\n",
    "  full_filename = os.path.join(filepath,str(i), filename)\n",
    "  file_exists = exists(full_filename)\n",
    "  if file_exists:\n",
    "    if i < 10:\n",
    "      j = full_filename[-16]\n",
    "      with open(full_filename, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "      lr.append(b['lr']) \n",
    "      epochs.append(b['epochs'])\n",
    "      batch_size.append(b['batch_size'])\n",
    "      print(\"array \" + str(j) + \" learning rate = \" + str(lr[int(j)]))\n",
    "      print(\"array \" + str(j) + \" epochs = \" + str(epochs[int(j)]))\n",
    "      print(\"array \" + str(j) + \" batch size = \" + str(batch_size[int(j)]))\n",
    "    elif i > 99:\n",
    "      j = int(full_filename[-18:-15]) \n",
    "      with open(full_filename, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "      lr.append(b['lr']) \n",
    "      epochs.append(b['epochs'])\n",
    "      batch_size.append(b['batch_size'])\n",
    "      print(\"array \" + str(j) + \" learning rate = \" + str(lr[j-h]))\n",
    "      print(\"array \" + str(j) + \" epochs = \" + str(epochs[j-h]))\n",
    "      print(\"array \" + str(j) + \" batch size = \" + str(batch_size[j-h]))\n",
    "    else:\n",
    "      j = int(full_filename[-17:-15]) \n",
    "      with open(full_filename, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "      lr.append(b['lr']) \n",
    "      epochs.append(b['epochs'])\n",
    "      batch_size.append(b['batch_size'])\n",
    "      print(\"array \" + str(j) + \" learning rate = \" + str(lr[j-h]))\n",
    "      print(\"array \" + str(j) + \" epochs = \" + str(epochs[j-h]))\n",
    "      print(\"array \" + str(j) + \" batch size = \" + str(batch_size[j-h]))\n",
    "  elif filetype == \"pt\":\n",
    "    print(torch.load(full_filename,map_location=torch.device('cpu')))\n",
    "  else:\n",
    "    print(full_filename + \" does not exist or is corrupted.\")\n",
    "    h += 1\n",
    "print(\"learning rate list:\" + str(lr)) \n",
    "print(\"epochs list: \" + str(epochs)) \n",
    "print(\"batch size list: \" + str(batch_size))\n",
    "print(\"final loss list: \" + str(loss))\n",
    "print('75th loss list: ' + str(seventy_fifth_loss))\n",
    "print('MATLAB loss epoch list: ' + str(epoch))\n",
    "print(\"learning rate list length: \" + str(len(lr))) \n",
    "print(\"epochs list length: \" + str(len(epochs))) \n",
    "print(\"batch size list length: \" + str(len(batch_size)))\n",
    "print(\"final loss list length: \" + str(len(loss)))\n",
    "print(\"75th loss list length: \" + str(len(seventy_fifth_loss)))\n",
    "print('MATLAB loss epoch list length: ' + str(len(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "learning rate",
           "values": [
            0.000015485873313524224,
            0.002423107963339815,
            0.010178534844817913,
            0.00030267426339163756,
            0.009239039877517135,
            0.08105255280156817,
            0.005119575903806145,
            0.000012444936348116345,
            0.004610841566767592,
            0.00026268235607603463,
            0.00001546058927618459,
            0.022399887666801968,
            0.0003761912835308907,
            0.0005525104065016169,
            0.000011899011269617424,
            0.0003602360488578598,
            0.01142744799302142,
            0.0013538685548585775,
            0.0001997785127635794,
            0.06262223564802699
           ]
          },
          {
           "label": "epochs",
           "values": [
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            10,
            80,
            80,
            80,
            80,
            80,
            80,
            80,
            80,
            80,
            80
           ]
          },
          {
           "label": "batch size",
           "values": [
            624,
            329,
            68,
            996,
            183,
            25,
            127,
            102,
            25,
            285,
            247,
            107,
            48,
            49,
            175,
            87,
            461,
            490,
            43,
            156
           ]
          },
          {
           "label": "MATLAB loss epoch",
           "values": [
            400,
            8,
            2,
            400,
            3,
            400,
            3,
            400,
            2,
            400,
            63,
            36,
            8,
            7,
            400,
            11,
            5,
            4,
            9,
            400
           ]
          }
         ],
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "line": {
          "color": [
           400,
           8,
           2,
           400,
           3,
           400,
           3,
           400,
           2,
           400,
           63,
           36,
           8,
           7,
           400,
           11,
           5,
           4,
           9,
           400
          ],
          "coloraxis": "coloraxis"
         },
         "name": "",
         "type": "parcoords"
        }
       ],
       "layout": {
        "coloraxis": {
         "cmid": 185,
         "colorbar": {
          "title": {
           "text": "MATLAB loss epoch"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(0, 147, 146)"
          ],
          [
           0.16666666666666666,
           "rgb(114, 170, 161)"
          ],
          [
           0.3333333333333333,
           "rgb(177, 199, 179)"
          ],
          [
           0.5,
           "rgb(241, 234, 200)"
          ],
          [
           0.6666666666666666,
           "rgb(229, 185, 173)"
          ],
          [
           0.8333333333333334,
           "rgb(217, 137, 148)"
          ],
          [
           1,
           "rgb(208, 88, 126)"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"57165613-13f8-47bd-a853-e75de7c7034e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"57165613-13f8-47bd-a853-e75de7c7034e\")) {                    Plotly.newPlot(                        \"57165613-13f8-47bd-a853-e75de7c7034e\",                        [{\"dimensions\":[{\"label\":\"learning rate\",\"values\":[1.5485873313524224e-05,0.002423107963339815,0.010178534844817913,0.00030267426339163756,0.009239039877517135,0.08105255280156817,0.005119575903806145,1.2444936348116345e-05,0.004610841566767592,0.00026268235607603463,1.546058927618459e-05,0.022399887666801968,0.0003761912835308907,0.0005525104065016169,1.1899011269617424e-05,0.0003602360488578598,0.01142744799302142,0.0013538685548585775,0.0001997785127635794,0.06262223564802699]},{\"label\":\"epochs\",\"values\":[10,10,10,10,10,10,10,10,10,10,80,80,80,80,80,80,80,80,80,80]},{\"label\":\"batch size\",\"values\":[624,329,68,996,183,25,127,102,25,285,247,107,48,49,175,87,461,490,43,156]},{\"label\":\"MATLAB loss epoch\",\"values\":[400,8,2,400,3,400,3,400,2,400,63,36,8,7,400,11,5,4,9,400]}],\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"line\":{\"color\":[400,8,2,400,3,400,3,400,2,400,63,36,8,7,400,11,5,4,9,400],\"coloraxis\":\"coloraxis\"},\"name\":\"\",\"type\":\"parcoords\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"MATLAB loss epoch\"}},\"colorscale\":[[0.0,\"rgb(0, 147, 146)\"],[0.16666666666666666,\"rgb(114, 170, 161)\"],[0.3333333333333333,\"rgb(177, 199, 179)\"],[0.5,\"rgb(241, 234, 200)\"],[0.6666666666666666,\"rgb(229, 185, 173)\"],[0.8333333333333334,\"rgb(217, 137, 148)\"],[1.0,\"rgb(208, 88, 126)\"]],\"cmid\":185},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('57165613-13f8-47bd-a853-e75de7c7034e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# MATLAB_loss_epoch= [31,7,43,6,397,2,400,73,79,None,53,14,3,10,9,8,8,14,6,10,7,11,9,31,6,7,71,7,13,109,34,39,400,17,None,400,51,6,11,400,6,425,31,154,4,15,400,None,169,2,10,27,9,15,67,102,6,12,27,11,23,19,5,4,6,8,18,39,44,400,53,4,8,94,400,400,34,33,400,11,400,27,46,39,8,8,35,47,400,16,53,21,400,35,40,15,91,400,102,26,22,85,28,36]\n",
    "# end_loss = [170.625,169.2216,169.881,172.6425,171.5856,171.4906,200.8244,171.4209,168.0032,None,170.4624,170.3961,168.8855,169.0507,169.3977,170.8383,169.5728,170.1414,170.4737,169.2979,170.8414,168.4813,170.9302,177.1033,170.127,175.239,172.0257,172.6612,170.4685,170.6348,173.9354,170.0953,182.8782,171.4582,None,174.7932,170.7267,169.7895,170.9821,177.5318,170.8467,170.7996,169.0987,172.5514,172.9049,168.9981,174.8774,None,171.8029,169.0201,170.1617,171.0394,164.014,170.8149,170.3139,169.9398,172.1823,170.3637,172.2119,172.2723,163.2362,171.8841,168.7147,170.7006,170.7408,171.6105,170.6718,171.2721,170.8758,173.928,174.0465,170.6715,169.985,170.9204,190.0418,179.1302,171.0091,172.7695,191.3036,169.4706,179.7738,172.5031,174.2779,172.9253,168.5179,170.9191,171.3534,168.7726,182.7285,171.5121,169.7371,171.7798,176.1571,175.0971,169.9502,169.1821,169.373,198.2109,170.2366,168.2848,168.9214,171.7177,170.0708,168.91]\n",
    "# MATLAB_loss_epoch = np.log10(np.array(MATLAB_loss_epoch,dtype=np.float32))\n",
    "# print(MATLAB_loss_epoch)\n",
    "df = pd.DataFrame(list(zip(lr, epochs, batch_size, loss, epoch)),\n",
    "               columns =['learning rate', 'epochs', 'batch size','final loss','MATLAB loss epoch'])\n",
    "\n",
    "fig = px.parallel_coordinates(df, color=\"MATLAB loss epoch\",\n",
    "                             color_continuous_scale=px.colors.diverging.Tealrose,\n",
    "                             color_continuous_midpoint=185)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch size</th>\n",
       "      <th>MATLAB loss epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001094</td>\n",
       "      <td>190</td>\n",
       "      <td>403</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002678</td>\n",
       "      <td>189</td>\n",
       "      <td>288</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>366</td>\n",
       "      <td>60</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000401</td>\n",
       "      <td>234</td>\n",
       "      <td>37</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>446</td>\n",
       "      <td>528</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005595</td>\n",
       "      <td>331</td>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>128</td>\n",
       "      <td>564</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>237</td>\n",
       "      <td>124</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>329</td>\n",
       "      <td>96</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000093</td>\n",
       "      <td>296</td>\n",
       "      <td>209</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004148</td>\n",
       "      <td>133</td>\n",
       "      <td>255</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000715</td>\n",
       "      <td>145</td>\n",
       "      <td>103</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.015360</td>\n",
       "      <td>329</td>\n",
       "      <td>28</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.002729</td>\n",
       "      <td>404</td>\n",
       "      <td>239</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.011674</td>\n",
       "      <td>408</td>\n",
       "      <td>121</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000046</td>\n",
       "      <td>123</td>\n",
       "      <td>100</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000180</td>\n",
       "      <td>120</td>\n",
       "      <td>28</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.002818</td>\n",
       "      <td>466</td>\n",
       "      <td>42</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.013037</td>\n",
       "      <td>122</td>\n",
       "      <td>39</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000555</td>\n",
       "      <td>266</td>\n",
       "      <td>353</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning rate  epochs  batch size  MATLAB loss epoch\n",
       "0        0.001094     190         403               31.0\n",
       "1        0.002678     189         288                7.0\n",
       "2        0.000025     366          60               43.0\n",
       "3        0.000401     234          37                6.0\n",
       "4        0.000030     446         528              397.0\n",
       "5        0.005595     331          23                2.0\n",
       "6        0.000026     128         564                NaN\n",
       "7        0.000031     237         124               73.0\n",
       "8        0.000033     329          96               79.0\n",
       "9        0.000093     296         209                NaN\n",
       "10       0.004148     133         255               53.0\n",
       "11       0.000715     145         103               14.0\n",
       "12       0.001000      75         100                3.0\n",
       "13       0.001000      75         100               10.0\n",
       "14       0.001000      75         100                9.0\n",
       "15       0.001000      75         100                8.0\n",
       "16       0.001000      75         100                8.0\n",
       "17       0.001000      75         100               14.0\n",
       "18       0.001000      75         100                6.0\n",
       "19       0.001000      75         100               10.0\n",
       "20       0.001000      75         100                7.0\n",
       "21       0.001000      75         100               11.0\n",
       "22       0.015360     329          28                9.0\n",
       "23       0.002729     404         239               31.0\n",
       "24       0.011674     408         121                6.0\n",
       "25       0.000046     123         100                7.0\n",
       "26       0.000180     120          28               71.0\n",
       "27       0.002818     466          42                7.0\n",
       "28       0.013037     122          39               13.0\n",
       "29       0.000555     266         353              109.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATLAB_loss_epoch= [31,7,43,6,397,2,None,73,79,None,53,14,3,10,9,8,8,14,6,10,7,11,9,31,6,7,71,7,13,109,34,39]\n",
    "df = pd.DataFrame(list(zip(lr, epochs, batch_size, MATLAB_loss_epoch)),\n",
    "                columns =['learning rate', 'epochs', 'batch size', 'MATLAB loss epoch'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ipy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a6bedd3509665544335308e415059c0a09ae1dacea269d4d09537be5f92701a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
