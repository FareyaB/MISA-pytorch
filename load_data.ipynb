{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array 0 learning rate = 0.0010939593299926363\n",
      "array 0 epochs = 190\n",
      "array 0 batch size = 403\n",
      "array 1 learning rate = 0.0026782974804180513\n",
      "array 1 epochs = 189\n",
      "array 1 batch size = 288\n",
      "array 2 learning rate = 2.5153955116192995e-05\n",
      "array 2 epochs = 366\n",
      "array 2 batch size = 60\n",
      "array 3 learning rate = 0.0004011790320607448\n",
      "array 3 epochs = 234\n",
      "array 3 batch size = 37\n",
      "array 4 learning rate = 3.0201977662690877e-05\n",
      "array 4 epochs = 446\n",
      "array 4 batch size = 528\n",
      "array 5 learning rate = 0.005595382398916672\n",
      "array 5 epochs = 331\n",
      "array 5 batch size = 23\n",
      "array 6 learning rate = 2.6212655214409847e-05\n",
      "array 6 epochs = 128\n",
      "array 6 batch size = 564\n",
      "array 7 learning rate = 3.10254772596167e-05\n",
      "array 7 epochs = 237\n",
      "array 7 batch size = 124\n",
      "array 8 learning rate = 3.329129787152935e-05\n",
      "array 8 epochs = 329\n",
      "array 8 batch size = 96\n",
      "/data/users2/dkhosravinezhad1/MISA-pytorch/run/9/res_sim-siva.p does not exist or is corrupted.\n",
      "array 10 learning rate = 9.331194785669017e-05\n",
      "array 10 epochs = 296\n",
      "array 10 batch size = 209\n",
      "array 11 learning rate = 0.004148093415001533\n",
      "array 11 epochs = 133\n",
      "array 11 batch size = 255\n",
      "array 12 learning rate = 0.0007153979838831962\n",
      "array 12 epochs = 145\n",
      "array 12 batch size = 103\n",
      "array 13 learning rate = 0.001\n",
      "array 13 epochs = 75\n",
      "array 13 batch size = 100\n",
      "array 14 learning rate = 0.001\n",
      "array 14 epochs = 75\n",
      "array 14 batch size = 100\n",
      "array 15 learning rate = 0.001\n",
      "array 15 epochs = 75\n",
      "array 15 batch size = 100\n",
      "array 16 learning rate = 0.001\n",
      "array 16 epochs = 75\n",
      "array 16 batch size = 100\n",
      "array 17 learning rate = 0.001\n",
      "array 17 epochs = 75\n",
      "array 17 batch size = 100\n",
      "array 18 learning rate = 0.001\n",
      "array 18 epochs = 75\n",
      "array 18 batch size = 100\n",
      "array 19 learning rate = 0.001\n",
      "array 19 epochs = 75\n",
      "array 19 batch size = 100\n",
      "array 20 learning rate = 0.001\n",
      "array 20 epochs = 75\n",
      "array 20 batch size = 100\n",
      "array 21 learning rate = 0.001\n",
      "array 21 epochs = 75\n",
      "array 21 batch size = 100\n",
      "array 22 learning rate = 0.001\n",
      "array 22 epochs = 75\n",
      "array 22 batch size = 100\n",
      "array 23 learning rate = 0.01536019285473459\n",
      "array 23 epochs = 329\n",
      "array 23 batch size = 28\n",
      "array 24 learning rate = 0.0027289724624635753\n",
      "array 24 epochs = 404\n",
      "array 24 batch size = 239\n",
      "array 25 learning rate = 0.011673683346051131\n",
      "array 25 epochs = 408\n",
      "array 25 batch size = 121\n",
      "array 26 learning rate = 4.649988966848756e-05\n",
      "array 26 epochs = 123\n",
      "array 26 batch size = 100\n",
      "array 27 learning rate = 0.00017993611427667952\n",
      "array 27 epochs = 120\n",
      "array 27 batch size = 28\n",
      "/data/users2/dkhosravinezhad1/MISA-pytorch/run/28/res_sim-siva.p does not exist or is corrupted.\n",
      "array 29 learning rate = 0.002817560644635271\n",
      "array 29 epochs = 466\n",
      "array 29 batch size = 42\n",
      "array 30 learning rate = 0.013037278993841488\n",
      "array 30 epochs = 122\n",
      "array 30 batch size = 39\n",
      "array 31 learning rate = 0.000555359409718051\n",
      "array 31 epochs = 266\n",
      "array 31 batch size = 353\n",
      "array 32 learning rate = 0.05150123542544886\n",
      "array 32 epochs = 103\n",
      "array 32 batch size = 49\n",
      "array 33 learning rate = 0.0006734052625524712\n",
      "array 33 epochs = 141\n",
      "array 33 batch size = 266\n",
      "/data/users2/dkhosravinezhad1/MISA-pytorch/run/34/res_sim-siva.p does not exist or is corrupted.\n",
      "array 35 learning rate = 0.020892688774914552\n",
      "array 35 epochs = 133\n",
      "array 35 batch size = 50\n",
      "array 36 learning rate = 0.0006013107711723952\n",
      "array 36 epochs = 296\n",
      "array 36 batch size = 696\n",
      "array 37 learning rate = 0.003481859810496369\n",
      "array 37 epochs = 105\n",
      "array 37 batch size = 392\n",
      "array 38 learning rate = 0.0006242274275827946\n",
      "array 38 epochs = 283\n",
      "array 38 batch size = 77\n",
      "array 39 learning rate = 0.041834768942315206\n",
      "array 39 epochs = 268\n",
      "array 39 batch size = 42\n",
      "array 40 learning rate = 0.000453015075991794\n",
      "array 40 epochs = 182\n",
      "array 40 batch size = 44\n",
      "array 41 learning rate = 3.732442066975105e-05\n",
      "array 41 epochs = 484\n",
      "array 41 batch size = 596\n",
      "array 42 learning rate = 0.00010902044659088149\n",
      "array 42 epochs = 135\n",
      "array 42 batch size = 73\n",
      "array 43 learning rate = 0.02561758704305381\n",
      "array 43 epochs = 180\n",
      "array 43 batch size = 205\n",
      "array 44 learning rate = 0.000492751319620853\n",
      "array 44 epochs = 113\n",
      "array 44 batch size = 119\n",
      "array 45 learning rate = 0.0047086887151148995\n",
      "array 45 epochs = 108\n",
      "array 45 batch size = 586\n",
      "array 46 learning rate = 0.08495524219960666\n",
      "array 46 epochs = 124\n",
      "array 46 batch size = 332\n",
      "/data/users2/dkhosravinezhad1/MISA-pytorch/run/47/res_sim-siva.p does not exist or is corrupted.\n",
      "array 48 learning rate = 2.984956988337801e-05\n",
      "array 48 epochs = 209\n",
      "array 48 batch size = 268\n",
      "array 49 learning rate = 0.0006079891342847671\n",
      "array 49 epochs = 292\n",
      "array 49 batch size = 23\n",
      "array 50 learning rate = 0.009574152404271835\n",
      "array 50 epochs = 375\n",
      "array 50 batch size = 930\n",
      "array 51 learning rate = 0.00021536525440193213\n",
      "array 51 epochs = 325\n",
      "array 51 batch size = 20\n",
      "array 52 learning rate = 0.0002445181688996255\n",
      "array 52 epochs = 118\n",
      "array 52 batch size = 49\n",
      "array 53 learning rate = 0.00012179660737838115\n",
      "array 53 epochs = 138\n",
      "array 53 batch size = 46\n",
      "array 54 learning rate = 0.0006204194544730138\n",
      "array 54 epochs = 176\n",
      "array 54 batch size = 650\n",
      "array 55 learning rate = 0.00013763736303666542\n",
      "array 55 epochs = 363\n",
      "array 55 batch size = 569\n",
      "array 56 learning rate = 0.0016347758453261806\n",
      "array 56 epochs = 377\n",
      "array 56 batch size = 90\n",
      "array 57 learning rate = 0.002515913605717074\n",
      "array 57 epochs = 240\n",
      "array 57 batch size = 576\n",
      "array 58 learning rate = 0.02768662429452156\n",
      "array 58 epochs = 186\n",
      "array 58 batch size = 568\n",
      "array 59 learning rate = 0.0031062718450551923\n",
      "array 59 epochs = 219\n",
      "array 59 batch size = 298\n",
      "array 60 learning rate = 3.896959138183326e-05\n",
      "array 60 epochs = 215\n",
      "array 60 batch size = 38\n",
      "array 61 learning rate = 0.015758375423044445\n",
      "array 61 epochs = 266\n",
      "array 61 batch size = 907\n",
      "array 62 learning rate = 0.0003679410250928206\n",
      "array 62 epochs = 283\n",
      "array 62 batch size = 63\n",
      "array 63 learning rate = 0.00433985003354171\n",
      "array 63 epochs = 392\n",
      "array 63 batch size = 70\n",
      "array 64 learning rate = 0.001716630288764904\n",
      "array 64 epochs = 246\n",
      "array 64 batch size = 210\n",
      "array 65 learning rate = 7.54937394539389e-05\n",
      "array 65 epochs = 276\n",
      "array 65 batch size = 28\n",
      "array 66 learning rate = 0.001459616939708491\n",
      "array 66 epochs = 112\n",
      "array 66 batch size = 403\n",
      "array 67 learning rate = 3.130437926999361e-05\n",
      "array 67 epochs = 356\n",
      "array 67 batch size = 54\n",
      "array 68 learning rate = 0.014820843674647506\n",
      "array 68 epochs = 104\n",
      "array 68 batch size = 329\n",
      "array 69 learning rate = 1.588331979276764e-05\n",
      "array 69 epochs = 290\n",
      "array 69 batch size = 371\n",
      "array 70 learning rate = 1.9635666329731288e-05\n",
      "array 70 epochs = 310\n",
      "array 70 batch size = 37\n",
      "array 71 learning rate = 0.005360244303737887\n",
      "array 71 epochs = 321\n",
      "array 71 batch size = 160\n",
      "array 72 learning rate = 0.000867123433454611\n",
      "array 72 epochs = 210\n",
      "array 72 batch size = 113\n",
      "array 73 learning rate = 0.00016170982076728688\n",
      "array 73 epochs = 113\n",
      "array 73 batch size = 403\n",
      "array 74 learning rate = 0.0798205733443793\n",
      "array 74 epochs = 141\n",
      "array 74 batch size = 64\n",
      "array 75 learning rate = 0.08581629373791982\n",
      "array 75 epochs = 155\n",
      "array 75 batch size = 240\n",
      "array 76 learning rate = 0.019454398751479526\n",
      "array 76 epochs = 211\n",
      "array 76 batch size = 630\n",
      "array 77 learning rate = 0.025764058649787234\n",
      "array 77 epochs = 261\n",
      "array 77 batch size = 321\n",
      "array 78 learning rate = 0.07161683150900224\n",
      "array 78 epochs = 279\n",
      "array 78 batch size = 23\n",
      "array 79 learning rate = 0.0056092871014781255\n",
      "array 79 epochs = 148\n",
      "array 79 batch size = 125\n",
      "array 80 learning rate = 2.5007597729218636e-05\n",
      "array 80 epochs = 121\n",
      "array 80 batch size = 289\n",
      "array 81 learning rate = 0.0034409477769646282\n",
      "array 81 epochs = 153\n",
      "array 81 batch size = 43\n",
      "array 82 learning rate = 0.02114378546577716\n",
      "array 82 epochs = 440\n",
      "array 82 batch size = 156\n",
      "array 83 learning rate = 0.016151040577859994\n",
      "array 83 epochs = 340\n",
      "array 83 batch size = 357\n",
      "array 84 learning rate = 0.0004969544761725491\n",
      "array 84 epochs = 301\n",
      "array 84 batch size = 69\n",
      "array 85 learning rate = 0.008197669890940921\n",
      "array 85 epochs = 132\n",
      "array 85 batch size = 705\n",
      "array 86 learning rate = 9.282379526377821e-05\n",
      "array 86 epochs = 208\n",
      "array 86 batch size = 120\n",
      "array 87 learning rate = 2.1129820127706568e-05\n",
      "array 87 epochs = 130\n",
      "array 87 batch size = 51\n",
      "array 88 learning rate = 0.028690702080829914\n",
      "array 88 epochs = 491\n",
      "array 88 batch size = 20\n",
      "array 89 learning rate = 0.03183159288557847\n",
      "array 89 epochs = 295\n",
      "array 89 batch size = 879\n",
      "array 90 learning rate = 3.8326589705517015e-05\n",
      "array 90 epochs = 163\n",
      "array 90 batch size = 57\n",
      "array 91 learning rate = 0.006905122520575674\n",
      "array 91 epochs = 388\n",
      "array 91 batch size = 40\n",
      "array 92 learning rate = 0.0412900536287527\n",
      "array 92 epochs = 386\n",
      "array 92 batch size = 121\n",
      "array 93 learning rate = 2.145414228982053e-05\n",
      "array 93 epochs = 128\n",
      "array 93 batch size = 38\n",
      "array 94 learning rate = 0.0006219190217659701\n",
      "array 94 epochs = 135\n",
      "array 94 batch size = 557\n",
      "array 95 learning rate = 0.0016495914395205234\n",
      "array 95 epochs = 327\n",
      "array 95 batch size = 70\n",
      "array 96 learning rate = 4.861245949342087e-05\n",
      "array 96 epochs = 393\n",
      "array 96 batch size = 235\n",
      "array 97 learning rate = 1.9731878631699096e-05\n",
      "array 97 epochs = 102\n",
      "array 97 batch size = 315\n",
      "array 98 learning rate = 0.0003371764337353747\n",
      "array 98 epochs = 218\n",
      "array 98 batch size = 930\n",
      "array 99 learning rate = 8.197296943845629e-05\n",
      "array 99 epochs = 140\n",
      "array 99 batch size = 30\n",
      "array 100 learning rate = 0.00033426193881543124\n",
      "array 100 epochs = 410\n",
      "array 100 batch size = 356\n",
      "array 101 learning rate = 0.02515534380882889\n",
      "array 101 epochs = 117\n",
      "array 101 batch size = 371\n",
      "array 102 learning rate = 0.001097479817651332\n",
      "array 102 epochs = 194\n",
      "array 102 batch size = 578\n",
      "array 103 learning rate = 0.00032232081236849145\n",
      "array 103 epochs = 214\n",
      "array 103 batch size = 168\n",
      "learning rate list:[0.0010939593299926363, 0.0026782974804180513, 2.5153955116192995e-05, 0.0004011790320607448, 3.0201977662690877e-05, 0.005595382398916672, 2.6212655214409847e-05, 3.10254772596167e-05, 3.329129787152935e-05, 9.331194785669017e-05, 0.004148093415001533, 0.0007153979838831962, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01536019285473459, 0.0027289724624635753, 0.011673683346051131, 4.649988966848756e-05, 0.00017993611427667952, 0.002817560644635271, 0.013037278993841488, 0.000555359409718051, 0.05150123542544886, 0.0006734052625524712, 0.020892688774914552, 0.0006013107711723952, 0.003481859810496369, 0.0006242274275827946, 0.041834768942315206, 0.000453015075991794, 3.732442066975105e-05, 0.00010902044659088149, 0.02561758704305381, 0.000492751319620853, 0.0047086887151148995, 0.08495524219960666, 2.984956988337801e-05, 0.0006079891342847671, 0.009574152404271835, 0.00021536525440193213, 0.0002445181688996255, 0.00012179660737838115, 0.0006204194544730138, 0.00013763736303666542, 0.0016347758453261806, 0.002515913605717074, 0.02768662429452156, 0.0031062718450551923, 3.896959138183326e-05, 0.015758375423044445, 0.0003679410250928206, 0.00433985003354171, 0.001716630288764904, 7.54937394539389e-05, 0.001459616939708491, 3.130437926999361e-05, 0.014820843674647506, 1.588331979276764e-05, 1.9635666329731288e-05, 0.005360244303737887, 0.000867123433454611, 0.00016170982076728688, 0.0798205733443793, 0.08581629373791982, 0.019454398751479526, 0.025764058649787234, 0.07161683150900224, 0.0056092871014781255, 2.5007597729218636e-05, 0.0034409477769646282, 0.02114378546577716, 0.016151040577859994, 0.0004969544761725491, 0.008197669890940921, 9.282379526377821e-05, 2.1129820127706568e-05, 0.028690702080829914, 0.03183159288557847, 3.8326589705517015e-05, 0.006905122520575674, 0.0412900536287527, 2.145414228982053e-05, 0.0006219190217659701, 0.0016495914395205234, 4.861245949342087e-05, 1.9731878631699096e-05, 0.0003371764337353747, 8.197296943845629e-05, 0.00033426193881543124, 0.02515534380882889, 0.001097479817651332, 0.00032232081236849145]\n",
      "epochs list: [190, 189, 366, 234, 446, 331, 128, 237, 329, 296, 133, 145, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 329, 404, 408, 123, 120, 466, 122, 266, 103, 141, 133, 296, 105, 283, 268, 182, 484, 135, 180, 113, 108, 124, 209, 292, 375, 325, 118, 138, 176, 363, 377, 240, 186, 219, 215, 266, 283, 392, 246, 276, 112, 356, 104, 290, 310, 321, 210, 113, 141, 155, 211, 261, 279, 148, 121, 153, 440, 340, 301, 132, 208, 130, 491, 295, 163, 388, 386, 128, 135, 327, 393, 102, 218, 140, 410, 117, 194, 214]\n",
      "batch size list: [403, 288, 60, 37, 528, 23, 564, 124, 96, 209, 255, 103, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 28, 239, 121, 100, 28, 42, 39, 353, 49, 266, 50, 696, 392, 77, 42, 44, 596, 73, 205, 119, 586, 332, 268, 23, 930, 20, 49, 46, 650, 569, 90, 576, 568, 298, 38, 907, 63, 70, 210, 28, 403, 54, 329, 371, 37, 160, 113, 403, 64, 240, 630, 321, 23, 125, 289, 43, 156, 357, 69, 705, 120, 51, 20, 879, 57, 40, 121, 38, 557, 70, 235, 315, 930, 30, 356, 371, 578, 168]\n",
      "learning rate list length: 100\n",
      "epochs list length: 100\n",
      "batch size list length: 100\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "filepath = '/data/users2/dkhosravinezhad1/MISA-pytorch/run'\n",
    "array_number = len(os.listdir(filepath)[2:])\n",
    "filename = 'res_sim-siva.p'# input(\"Insert file directory here: \")\n",
    "objects = []\n",
    "filetype = filename[-2:]\n",
    "lr = []\n",
    "epochs = []\n",
    "batch_size = []\n",
    "h = 0\n",
    "for i in range(array_number):\n",
    "  full_filename = os.path.join(filepath,str(i), filename)\n",
    "  file_exists = exists(full_filename)\n",
    "  if file_exists:\n",
    "    if i < 10:\n",
    "      j = full_filename[-16]\n",
    "      with open(full_filename, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "      lr.append(b['lr']) \n",
    "      epochs.append(b['epochs'])\n",
    "      batch_size.append(b['batch_size'])\n",
    "      print(\"array \" + str(j) + \" learning rate = \" + str(lr[int(j)]))\n",
    "      print(\"array \" + str(j) + \" epochs = \" + str(epochs[int(j)]))\n",
    "      print(\"array \" + str(j) + \" batch size = \" + str(batch_size[int(j)]))\n",
    "    elif i > 99:\n",
    "      j = int(full_filename[-18:-15]) \n",
    "      with open(full_filename, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "      lr.append(b['lr']) \n",
    "      epochs.append(b['epochs'])\n",
    "      batch_size.append(b['batch_size'])\n",
    "      print(\"array \" + str(j) + \" learning rate = \" + str(lr[j-h]))\n",
    "      print(\"array \" + str(j) + \" epochs = \" + str(epochs[j-h]))\n",
    "      print(\"array \" + str(j) + \" batch size = \" + str(batch_size[j-h]))\n",
    "    else:\n",
    "      j = int(full_filename[-17:-15]) \n",
    "      with open(full_filename, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "      lr.append(b['lr']) \n",
    "      epochs.append(b['epochs'])\n",
    "      batch_size.append(b['batch_size'])\n",
    "      print(\"array \" + str(j) + \" learning rate = \" + str(lr[j-h]))\n",
    "      print(\"array \" + str(j) + \" epochs = \" + str(epochs[j-h]))\n",
    "      print(\"array \" + str(j) + \" batch size = \" + str(batch_size[j-h]))\n",
    "  elif filetype == \"pt\":\n",
    "    print(torch.load(full_filename,map_location=torch.device('cpu')))\n",
    "  else:\n",
    "    print(full_filename + \" does not exist or is corrupted.\")\n",
    "    h += 1\n",
    "print(\"learning rate list:\" + str(lr)) \n",
    "print(\"epochs list: \" + str(epochs)) \n",
    "print(\"batch size list: \" + str(batch_size))\n",
    "print(\"learning rate list length: \" + str(len(lr))) \n",
    "print(\"epochs list length: \" + str(len(epochs))) \n",
    "print(\"batch size list length: \" + str(len(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "learning rate",
           "values": [
            0.0010939593299926363,
            0.0026782974804180513,
            0.000025153955116192995,
            0.0004011790320607448,
            0.000030201977662690877,
            0.005595382398916672,
            0.000026212655214409847,
            0.0000310254772596167,
            0.00003329129787152935,
            0.00009331194785669017,
            0.004148093415001533,
            0.0007153979838831962,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.001,
            0.01536019285473459,
            0.0027289724624635753,
            0.011673683346051131,
            0.00004649988966848756,
            0.00017993611427667952,
            0.002817560644635271,
            0.013037278993841488,
            0.000555359409718051,
            0.05150123542544886,
            0.0006734052625524712,
            0.020892688774914552,
            0.0006013107711723952,
            0.003481859810496369,
            0.0006242274275827946,
            0.041834768942315206,
            0.000453015075991794,
            0.00003732442066975105,
            0.00010902044659088149,
            0.02561758704305381,
            0.000492751319620853,
            0.0047086887151148995,
            0.08495524219960666,
            0.00002984956988337801,
            0.0006079891342847671,
            0.009574152404271835,
            0.00021536525440193213,
            0.0002445181688996255,
            0.00012179660737838115,
            0.0006204194544730138,
            0.00013763736303666542,
            0.0016347758453261806,
            0.002515913605717074,
            0.02768662429452156,
            0.0031062718450551923,
            0.00003896959138183326,
            0.015758375423044445,
            0.0003679410250928206,
            0.00433985003354171,
            0.001716630288764904,
            0.0000754937394539389,
            0.001459616939708491,
            0.00003130437926999361,
            0.014820843674647506,
            0.00001588331979276764,
            0.000019635666329731288,
            0.005360244303737887,
            0.000867123433454611,
            0.00016170982076728688,
            0.0798205733443793,
            0.08581629373791982,
            0.019454398751479526,
            0.025764058649787234,
            0.07161683150900224,
            0.0056092871014781255,
            0.000025007597729218636,
            0.0034409477769646282,
            0.02114378546577716,
            0.016151040577859994,
            0.0004969544761725491,
            0.008197669890940921,
            0.00009282379526377821,
            0.000021129820127706568,
            0.028690702080829914,
            0.03183159288557847,
            0.000038326589705517015,
            0.006905122520575674,
            0.0412900536287527,
            0.00002145414228982053,
            0.0006219190217659701,
            0.0016495914395205234,
            0.00004861245949342087,
            0.000019731878631699096,
            0.0003371764337353747,
            0.00008197296943845629,
            0.00033426193881543124,
            0.02515534380882889,
            0.001097479817651332,
            0.00032232081236849145
           ]
          },
          {
           "label": "epochs",
           "values": [
            190,
            189,
            366,
            234,
            446,
            331,
            128,
            237,
            329,
            296,
            133,
            145,
            75,
            75,
            75,
            75,
            75,
            75,
            75,
            75,
            75,
            75,
            329,
            404,
            408,
            123,
            120,
            466,
            122,
            266,
            103,
            141,
            133,
            296,
            105,
            283,
            268,
            182,
            484,
            135,
            180,
            113,
            108,
            124,
            209,
            292,
            375,
            325,
            118,
            138,
            176,
            363,
            377,
            240,
            186,
            219,
            215,
            266,
            283,
            392,
            246,
            276,
            112,
            356,
            104,
            290,
            310,
            321,
            210,
            113,
            141,
            155,
            211,
            261,
            279,
            148,
            121,
            153,
            440,
            340,
            301,
            132,
            208,
            130,
            491,
            295,
            163,
            388,
            386,
            128,
            135,
            327,
            393,
            102,
            218,
            140,
            410,
            117,
            194,
            214
           ]
          },
          {
           "label": "batch size",
           "values": [
            403,
            288,
            60,
            37,
            528,
            23,
            564,
            124,
            96,
            209,
            255,
            103,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            28,
            239,
            121,
            100,
            28,
            42,
            39,
            353,
            49,
            266,
            50,
            696,
            392,
            77,
            42,
            44,
            596,
            73,
            205,
            119,
            586,
            332,
            268,
            23,
            930,
            20,
            49,
            46,
            650,
            569,
            90,
            576,
            568,
            298,
            38,
            907,
            63,
            70,
            210,
            28,
            403,
            54,
            329,
            371,
            37,
            160,
            113,
            403,
            64,
            240,
            630,
            321,
            23,
            125,
            289,
            43,
            156,
            357,
            69,
            705,
            120,
            51,
            20,
            879,
            57,
            40,
            121,
            38,
            557,
            70,
            235,
            315,
            930,
            30,
            356,
            371,
            578,
            168
           ]
          },
          {
           "label": "final loss",
           "values": [
            170.625,
            169.2216,
            169.881,
            172.6425,
            171.5856,
            171.4906,
            200.8244,
            171.4209,
            168.0032,
            null,
            170.4624,
            170.3961,
            168.8855,
            169.0507,
            169.3977,
            170.8383,
            169.5728,
            170.1414,
            170.4737,
            169.2979,
            170.8414,
            168.4813,
            170.9302,
            177.1033,
            170.127,
            175.239,
            172.0257,
            172.6612,
            170.4685,
            170.6348,
            173.9354,
            170.0953,
            182.8782,
            171.4582,
            null,
            174.7932,
            170.7267,
            169.7895,
            170.9821,
            177.5318,
            170.8467,
            170.7996,
            169.0987,
            172.5514,
            172.9049,
            168.9981,
            174.8774,
            null,
            171.8029,
            169.0201,
            170.1617,
            171.0394,
            164.014,
            170.8149,
            170.3139,
            169.9398,
            172.1823,
            170.3637,
            172.2119,
            172.2723,
            163.2362,
            171.8841,
            168.7147,
            170.7006,
            170.7408,
            171.6105,
            170.6718,
            171.2721,
            170.8758,
            173.928,
            174.0465,
            170.6715,
            169.985,
            170.9204,
            190.0418,
            179.1302,
            171.0091,
            172.7695,
            191.3036,
            169.4706,
            179.7738,
            172.5031,
            174.2779,
            172.9253,
            168.5179,
            170.9191,
            171.3534,
            168.7726,
            182.7285,
            171.5121,
            169.7371,
            171.7798,
            176.1571,
            175.0971,
            169.9502,
            169.1821,
            169.373,
            198.2109,
            170.2366,
            168.2848
           ]
          },
          {
           "label": "MATLAB loss epoch",
           "values": [
            31,
            7,
            43,
            6,
            397,
            2,
            400,
            73,
            79,
            null,
            53,
            14,
            3,
            10,
            9,
            8,
            8,
            14,
            6,
            10,
            7,
            11,
            9,
            31,
            6,
            7,
            71,
            7,
            13,
            109,
            34,
            39,
            400,
            17,
            null,
            400,
            51,
            6,
            11,
            400,
            6,
            425,
            31,
            154,
            4,
            15,
            400,
            null,
            169,
            2,
            10,
            27,
            9,
            15,
            67,
            102,
            6,
            12,
            27,
            11,
            23,
            19,
            5,
            4,
            6,
            8,
            18,
            39,
            44,
            400,
            53,
            4,
            8,
            94,
            400,
            400,
            34,
            33,
            400,
            11,
            400,
            27,
            46,
            39,
            8,
            8,
            35,
            47,
            400,
            16,
            53,
            21,
            400,
            35,
            40,
            15,
            91,
            400,
            102,
            26
           ]
          }
         ],
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "line": {
          "color": [
           31,
           7,
           43,
           6,
           397,
           2,
           400,
           73,
           79,
           null,
           53,
           14,
           3,
           10,
           9,
           8,
           8,
           14,
           6,
           10,
           7,
           11,
           9,
           31,
           6,
           7,
           71,
           7,
           13,
           109,
           34,
           39,
           400,
           17,
           null,
           400,
           51,
           6,
           11,
           400,
           6,
           425,
           31,
           154,
           4,
           15,
           400,
           null,
           169,
           2,
           10,
           27,
           9,
           15,
           67,
           102,
           6,
           12,
           27,
           11,
           23,
           19,
           5,
           4,
           6,
           8,
           18,
           39,
           44,
           400,
           53,
           4,
           8,
           94,
           400,
           400,
           34,
           33,
           400,
           11,
           400,
           27,
           46,
           39,
           8,
           8,
           35,
           47,
           400,
           16,
           53,
           21,
           400,
           35,
           40,
           15,
           91,
           400,
           102,
           26
          ],
          "coloraxis": "coloraxis"
         },
         "name": "",
         "type": "parcoords"
        }
       ],
       "layout": {
        "coloraxis": {
         "cmid": 185,
         "colorbar": {
          "title": {
           "text": "MATLAB loss epoch"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(0, 147, 146)"
          ],
          [
           0.16666666666666666,
           "rgb(114, 170, 161)"
          ],
          [
           0.3333333333333333,
           "rgb(177, 199, 179)"
          ],
          [
           0.5,
           "rgb(241, 234, 200)"
          ],
          [
           0.6666666666666666,
           "rgb(229, 185, 173)"
          ],
          [
           0.8333333333333334,
           "rgb(217, 137, 148)"
          ],
          [
           1,
           "rgb(208, 88, 126)"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"45ab57c4-bc17-4d12-8d7f-d1779d0926fd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"45ab57c4-bc17-4d12-8d7f-d1779d0926fd\")) {                    Plotly.newPlot(                        \"45ab57c4-bc17-4d12-8d7f-d1779d0926fd\",                        [{\"dimensions\":[{\"label\":\"learning rate\",\"values\":[0.0010939593299926363,0.0026782974804180513,2.5153955116192995e-05,0.0004011790320607448,3.0201977662690877e-05,0.005595382398916672,2.6212655214409847e-05,3.10254772596167e-05,3.329129787152935e-05,9.331194785669017e-05,0.004148093415001533,0.0007153979838831962,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.001,0.01536019285473459,0.0027289724624635753,0.011673683346051131,4.649988966848756e-05,0.00017993611427667952,0.002817560644635271,0.013037278993841488,0.000555359409718051,0.05150123542544886,0.0006734052625524712,0.020892688774914552,0.0006013107711723952,0.003481859810496369,0.0006242274275827946,0.041834768942315206,0.000453015075991794,3.732442066975105e-05,0.00010902044659088149,0.02561758704305381,0.000492751319620853,0.0047086887151148995,0.08495524219960666,2.984956988337801e-05,0.0006079891342847671,0.009574152404271835,0.00021536525440193213,0.0002445181688996255,0.00012179660737838115,0.0006204194544730138,0.00013763736303666542,0.0016347758453261806,0.002515913605717074,0.02768662429452156,0.0031062718450551923,3.896959138183326e-05,0.015758375423044445,0.0003679410250928206,0.00433985003354171,0.001716630288764904,7.54937394539389e-05,0.001459616939708491,3.130437926999361e-05,0.014820843674647506,1.588331979276764e-05,1.9635666329731288e-05,0.005360244303737887,0.000867123433454611,0.00016170982076728688,0.0798205733443793,0.08581629373791982,0.019454398751479526,0.025764058649787234,0.07161683150900224,0.0056092871014781255,2.5007597729218636e-05,0.0034409477769646282,0.02114378546577716,0.016151040577859994,0.0004969544761725491,0.008197669890940921,9.282379526377821e-05,2.1129820127706568e-05,0.028690702080829914,0.03183159288557847,3.8326589705517015e-05,0.006905122520575674,0.0412900536287527,2.145414228982053e-05,0.0006219190217659701,0.0016495914395205234,4.861245949342087e-05,1.9731878631699096e-05,0.0003371764337353747,8.197296943845629e-05,0.00033426193881543124,0.02515534380882889,0.001097479817651332,0.00032232081236849145]},{\"label\":\"epochs\",\"values\":[190,189,366,234,446,331,128,237,329,296,133,145,75,75,75,75,75,75,75,75,75,75,329,404,408,123,120,466,122,266,103,141,133,296,105,283,268,182,484,135,180,113,108,124,209,292,375,325,118,138,176,363,377,240,186,219,215,266,283,392,246,276,112,356,104,290,310,321,210,113,141,155,211,261,279,148,121,153,440,340,301,132,208,130,491,295,163,388,386,128,135,327,393,102,218,140,410,117,194,214]},{\"label\":\"batch size\",\"values\":[403,288,60,37,528,23,564,124,96,209,255,103,100,100,100,100,100,100,100,100,100,100,28,239,121,100,28,42,39,353,49,266,50,696,392,77,42,44,596,73,205,119,586,332,268,23,930,20,49,46,650,569,90,576,568,298,38,907,63,70,210,28,403,54,329,371,37,160,113,403,64,240,630,321,23,125,289,43,156,357,69,705,120,51,20,879,57,40,121,38,557,70,235,315,930,30,356,371,578,168]},{\"label\":\"final loss\",\"values\":[170.625,169.2216,169.881,172.6425,171.5856,171.4906,200.8244,171.4209,168.0032,null,170.4624,170.3961,168.8855,169.0507,169.3977,170.8383,169.5728,170.1414,170.4737,169.2979,170.8414,168.4813,170.9302,177.1033,170.127,175.239,172.0257,172.6612,170.4685,170.6348,173.9354,170.0953,182.8782,171.4582,null,174.7932,170.7267,169.7895,170.9821,177.5318,170.8467,170.7996,169.0987,172.5514,172.9049,168.9981,174.8774,null,171.8029,169.0201,170.1617,171.0394,164.014,170.8149,170.3139,169.9398,172.1823,170.3637,172.2119,172.2723,163.2362,171.8841,168.7147,170.7006,170.7408,171.6105,170.6718,171.2721,170.8758,173.928,174.0465,170.6715,169.985,170.9204,190.0418,179.1302,171.0091,172.7695,191.3036,169.4706,179.7738,172.5031,174.2779,172.9253,168.5179,170.9191,171.3534,168.7726,182.7285,171.5121,169.7371,171.7798,176.1571,175.0971,169.9502,169.1821,169.373,198.2109,170.2366,168.2848]},{\"label\":\"MATLAB loss epoch\",\"values\":[31.0,7.0,43.0,6.0,397.0,2.0,400.0,73.0,79.0,null,53.0,14.0,3.0,10.0,9.0,8.0,8.0,14.0,6.0,10.0,7.0,11.0,9.0,31.0,6.0,7.0,71.0,7.0,13.0,109.0,34.0,39.0,400.0,17.0,null,400.0,51.0,6.0,11.0,400.0,6.0,425.0,31.0,154.0,4.0,15.0,400.0,null,169.0,2.0,10.0,27.0,9.0,15.0,67.0,102.0,6.0,12.0,27.0,11.0,23.0,19.0,5.0,4.0,6.0,8.0,18.0,39.0,44.0,400.0,53.0,4.0,8.0,94.0,400.0,400.0,34.0,33.0,400.0,11.0,400.0,27.0,46.0,39.0,8.0,8.0,35.0,47.0,400.0,16.0,53.0,21.0,400.0,35.0,40.0,15.0,91.0,400.0,102.0,26.0]}],\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"line\":{\"color\":[31.0,7.0,43.0,6.0,397.0,2.0,400.0,73.0,79.0,null,53.0,14.0,3.0,10.0,9.0,8.0,8.0,14.0,6.0,10.0,7.0,11.0,9.0,31.0,6.0,7.0,71.0,7.0,13.0,109.0,34.0,39.0,400.0,17.0,null,400.0,51.0,6.0,11.0,400.0,6.0,425.0,31.0,154.0,4.0,15.0,400.0,null,169.0,2.0,10.0,27.0,9.0,15.0,67.0,102.0,6.0,12.0,27.0,11.0,23.0,19.0,5.0,4.0,6.0,8.0,18.0,39.0,44.0,400.0,53.0,4.0,8.0,94.0,400.0,400.0,34.0,33.0,400.0,11.0,400.0,27.0,46.0,39.0,8.0,8.0,35.0,47.0,400.0,16.0,53.0,21.0,400.0,35.0,40.0,15.0,91.0,400.0,102.0,26.0],\"coloraxis\":\"coloraxis\"},\"name\":\"\",\"type\":\"parcoords\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"MATLAB loss epoch\"}},\"colorscale\":[[0.0,\"rgb(0, 147, 146)\"],[0.16666666666666666,\"rgb(114, 170, 161)\"],[0.3333333333333333,\"rgb(177, 199, 179)\"],[0.5,\"rgb(241, 234, 200)\"],[0.6666666666666666,\"rgb(229, 185, 173)\"],[0.8333333333333334,\"rgb(217, 137, 148)\"],[1.0,\"rgb(208, 88, 126)\"]],\"cmid\":185},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('45ab57c4-bc17-4d12-8d7f-d1779d0926fd');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "MATLAB_loss_epoch= [31,7,43,6,397,2,400,73,79,None,53,14,3,10,9,8,8,14,6,10,7,11,9,31,6,7,71,7,13,109,34,39,400,17,None,400,51,6,11,400,6,425,31,154,4,15,400,None,169,2,10,27,9,15,67,102,6,12,27,11,23,19,5,4,6,8,18,39,44,400,53,4,8,94,400,400,34,33,400,11,400,27,46,39,8,8,35,47,400,16,53,21,400,35,40,15,91,400,102,26,22,85,28,36]\n",
    "end_loss = [170.625,169.2216,169.881,172.6425,171.5856,171.4906,200.8244,171.4209,168.0032,None,170.4624,170.3961,168.8855,169.0507,169.3977,170.8383,169.5728,170.1414,170.4737,169.2979,170.8414,168.4813,170.9302,177.1033,170.127,175.239,172.0257,172.6612,170.4685,170.6348,173.9354,170.0953,182.8782,171.4582,None,174.7932,170.7267,169.7895,170.9821,177.5318,170.8467,170.7996,169.0987,172.5514,172.9049,168.9981,174.8774,None,171.8029,169.0201,170.1617,171.0394,164.014,170.8149,170.3139,169.9398,172.1823,170.3637,172.2119,172.2723,163.2362,171.8841,168.7147,170.7006,170.7408,171.6105,170.6718,171.2721,170.8758,173.928,174.0465,170.6715,169.985,170.9204,190.0418,179.1302,171.0091,172.7695,191.3036,169.4706,179.7738,172.5031,174.2779,172.9253,168.5179,170.9191,171.3534,168.7726,182.7285,171.5121,169.7371,171.7798,176.1571,175.0971,169.9502,169.1821,169.373,198.2109,170.2366,168.2848,168.9214,171.7177,170.0708,168.91]\n",
    "# MATLAB_loss_epoch = np.log10(np.array(MATLAB_loss_epoch,dtype=np.float32))\n",
    "# print(MATLAB_loss_epoch)\n",
    "df = pd.DataFrame(list(zip(lr, epochs, batch_size, end_loss, MATLAB_loss_epoch)),\n",
    "               columns =['learning rate', 'epochs', 'batch size','final loss','MATLAB loss epoch'])\n",
    "\n",
    "fig = px.parallel_coordinates(df, color=\"MATLAB loss epoch\",\n",
    "                             color_continuous_scale=px.colors.diverging.Tealrose,\n",
    "                             color_continuous_midpoint=185)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch size</th>\n",
       "      <th>MATLAB loss epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001094</td>\n",
       "      <td>190</td>\n",
       "      <td>403</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002678</td>\n",
       "      <td>189</td>\n",
       "      <td>288</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>366</td>\n",
       "      <td>60</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000401</td>\n",
       "      <td>234</td>\n",
       "      <td>37</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>446</td>\n",
       "      <td>528</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005595</td>\n",
       "      <td>331</td>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>128</td>\n",
       "      <td>564</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>237</td>\n",
       "      <td>124</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>329</td>\n",
       "      <td>96</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000093</td>\n",
       "      <td>296</td>\n",
       "      <td>209</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004148</td>\n",
       "      <td>133</td>\n",
       "      <td>255</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000715</td>\n",
       "      <td>145</td>\n",
       "      <td>103</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.015360</td>\n",
       "      <td>329</td>\n",
       "      <td>28</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.002729</td>\n",
       "      <td>404</td>\n",
       "      <td>239</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.011674</td>\n",
       "      <td>408</td>\n",
       "      <td>121</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000046</td>\n",
       "      <td>123</td>\n",
       "      <td>100</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000180</td>\n",
       "      <td>120</td>\n",
       "      <td>28</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.002818</td>\n",
       "      <td>466</td>\n",
       "      <td>42</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.013037</td>\n",
       "      <td>122</td>\n",
       "      <td>39</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000555</td>\n",
       "      <td>266</td>\n",
       "      <td>353</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning rate  epochs  batch size  MATLAB loss epoch\n",
       "0        0.001094     190         403               31.0\n",
       "1        0.002678     189         288                7.0\n",
       "2        0.000025     366          60               43.0\n",
       "3        0.000401     234          37                6.0\n",
       "4        0.000030     446         528              397.0\n",
       "5        0.005595     331          23                2.0\n",
       "6        0.000026     128         564                NaN\n",
       "7        0.000031     237         124               73.0\n",
       "8        0.000033     329          96               79.0\n",
       "9        0.000093     296         209                NaN\n",
       "10       0.004148     133         255               53.0\n",
       "11       0.000715     145         103               14.0\n",
       "12       0.001000      75         100                3.0\n",
       "13       0.001000      75         100               10.0\n",
       "14       0.001000      75         100                9.0\n",
       "15       0.001000      75         100                8.0\n",
       "16       0.001000      75         100                8.0\n",
       "17       0.001000      75         100               14.0\n",
       "18       0.001000      75         100                6.0\n",
       "19       0.001000      75         100               10.0\n",
       "20       0.001000      75         100                7.0\n",
       "21       0.001000      75         100               11.0\n",
       "22       0.015360     329          28                9.0\n",
       "23       0.002729     404         239               31.0\n",
       "24       0.011674     408         121                6.0\n",
       "25       0.000046     123         100                7.0\n",
       "26       0.000180     120          28               71.0\n",
       "27       0.002818     466          42                7.0\n",
       "28       0.013037     122          39               13.0\n",
       "29       0.000555     266         353              109.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATLAB_loss_epoch= [31,7,43,6,397,2,None,73,79,None,53,14,3,10,9,8,8,14,6,10,7,11,9,31,6,7,71,7,13,109,34,39]\n",
    "df = pd.DataFrame(list(zip(lr, epochs, batch_size, MATLAB_loss_epoch)),\n",
    "                columns =['learning rate', 'epochs', 'batch size', 'MATLAB loss epoch'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ipy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a6bedd3509665544335308e415059c0a09ae1dacea269d4d09537be5f92701a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
