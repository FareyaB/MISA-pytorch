{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement HistGradientBoostingClassifier (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for HistGradientBoostingClassifier\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/data/users2/dkhosravinezhad1/MISA-pytorch/slurm/scikit.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdevtrends01/data/users2/dkhosravinezhad1/MISA-pytorch/slurm/scikit.ipynb#ch0000000vscode-remote?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m loguniform\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdevtrends01/data/users2/dkhosravinezhad1/MISA-pytorch/slurm/scikit.ipynb#ch0000000vscode-remote?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdevtrends01/data/users2/dkhosravinezhad1/MISA-pytorch/slurm/scikit.ipynb#ch0000000vscode-remote?line=11'>12</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdataset\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdata\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdevtrends01/data/users2/dkhosravinezhad1/MISA-pytorch/slurm/scikit.ipynb#ch0000000vscode-remote?line=13'>14</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mloguniform_int\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdevtrends01/data/users2/dkhosravinezhad1/MISA-pytorch/slurm/scikit.ipynb#ch0000000vscode-remote?line=14'>15</a>\u001b[0m     \u001b[39m\"\"\"Integer valued version of the log-uniform distribution\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataset'"
     ]
    }
   ],
   "source": [
    "%pip install HistGradientBoostingClassifier\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import loguniform\n",
    "import pandas as pd\n",
    "import dataset.dataset as data\n",
    "\n",
    "class loguniform_int:\n",
    "    \"\"\"Integer valued version of the log-uniform distribution\"\"\"\n",
    "    def __init__(self, a, b):\n",
    "        self._distribution = loguniform(a, b)\n",
    "\n",
    "    def rvs(self, *args, **kwargs):\n",
    "        \"\"\"Random variable sample\"\"\"\n",
    "        return self._distribution.rvs(*args, **kwargs).astype(int)\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, 'target', random_state=42)\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "categorical_columns = categorical_columns_selector(data)\n",
    "\n",
    "categorical_preprocessor = OrdinalEncoder(handle_unknown=\"use_encoded_value\",\n",
    "                                          unknown_value=-1)\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat_preprocessor', categorical_preprocessor, categorical_columns)],\n",
    "    remainder='passthrough', sparse_threshold=0)\n",
    "model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", HistGradientBoostingClassifier(random_state=42, max_leaf_nodes=4)),\n",
    "])\n",
    "\n",
    "model\n",
    "param_distributions = {\n",
    "    'classifier__l2_regularization': loguniform(1e-6, 1e3),\n",
    "    'classifier__learning_rate': loguniform(0.001, 10),\n",
    "    'classifier__max_leaf_nodes': loguniform_int(2, 256),\n",
    "    'classifier__min_samples_leaf': loguniform_int(1, 100),\n",
    "    'classifier__max_bins': loguniform_int(2, 255),\n",
    "}\n",
    "\n",
    "model_random_search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_distributions, n_iter=10,\n",
    "    cv=5, verbose=1,\n",
    ")\n",
    "model_random_search.fit(data_train, target_train)\n",
    "accuracy = model_random_search.score(data_test, target_test)\n",
    "\n",
    "print(f\"The test accuracy score of the best model is \"\n",
    "      f\"{accuracy:.2f}\")\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"The best parameters are:\")\n",
    "pprint(model_random_search.best_params_)\n",
    "# get the parameter names\n",
    "column_results = [\n",
    "    f\"param_{name}\" for name in param_distributions.keys()]\n",
    "column_results += [\n",
    "    \"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n",
    "\n",
    "cv_results = pd.DataFrame(model_random_search.cv_results_)\n",
    "cv_results = cv_results[column_results].sort_values(\n",
    "    \"mean_test_score\", ascending=False)\n",
    "\n",
    "def shorten_param(param_name):\n",
    "    if \"__\" in param_name:\n",
    "        return param_name.rsplit(\"__\", 1)[1]\n",
    "    return param_name\n",
    "\n",
    "cv_results = cv_results.rename(shorten_param, axis=1)\n",
    "cv_results\n",
    "cv_results = pd.read_csv(\"../figures/randomized_search_results.csv\",\n",
    "                         index_col=0)\n",
    "\n",
    "(cv_results[column_results].rename(\n",
    "    shorten_param, axis=1).sort_values(\"mean_test_score\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement HistGradientBoostingClassifier (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for HistGradientBoostingClassifier\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HistGradientBoostingClassifier' from 'sklearn.ensemble' (/data/users2/dkhosravinezhad1/anaconda3/envs/ipy/lib/python3.8/site-packages/sklearn/ensemble/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/data/users2/dkhosravinezhad1/MISA-pytorch/slurm/scikit.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdevtrends01/data/users2/dkhosravinezhad1/MISA-pytorch/slurm/scikit.ipynb#ch0000001vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompose\u001b[39;00m \u001b[39mimport\u001b[39;00m make_column_selector \u001b[39mas\u001b[39;00m selector\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdevtrends01/data/users2/dkhosravinezhad1/MISA-pytorch/slurm/scikit.ipynb#ch0000001vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompose\u001b[39;00m \u001b[39mimport\u001b[39;00m ColumnTransformer\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdevtrends01/data/users2/dkhosravinezhad1/MISA-pytorch/slurm/scikit.ipynb#ch0000001vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m HistGradientBoostingClassifier\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdevtrends01/data/users2/dkhosravinezhad1/MISA-pytorch/slurm/scikit.ipynb#ch0000001vscode-remote?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpipeline\u001b[39;00m \u001b[39mimport\u001b[39;00m Pipeline\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdevtrends01/data/users2/dkhosravinezhad1/MISA-pytorch/slurm/scikit.ipynb#ch0000001vscode-remote?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m loguniform\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'HistGradientBoostingClassifier' from 'sklearn.ensemble' (/data/users2/dkhosravinezhad1/anaconda3/envs/ipy/lib/python3.8/site-packages/sklearn/ensemble/__init__.py)"
     ]
    }
   ],
   "source": [
    "%pip install HistGradientBoostingClassifier\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import loguniform\n",
    "import pandas as pd\n",
    "from dataset.dataset import Dataset as data\n",
    "\n",
    "class loguniform_int:\n",
    "    \"\"\"Integer valued version of the log-uniform distribution\"\"\"\n",
    "    def __init__(self, a, b):\n",
    "        self._distribution = loguniform(a, b)\n",
    "\n",
    "    def rvs(self, *args, **kwargs):\n",
    "        \"\"\"Random variable sample\"\"\"\n",
    "        return self._distribution.rvs(*args, **kwargs).astype(int)\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, 'target', random_state=42)\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "categorical_columns = categorical_columns_selector(data)\n",
    "\n",
    "categorical_preprocessor = OrdinalEncoder(handle_unknown=\"use_encoded_value\",\n",
    "                                          unknown_value=-1)\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat_preprocessor', categorical_preprocessor, categorical_columns)],\n",
    "    remainder='passthrough', sparse_threshold=0)\n",
    "model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", HistGradientBoostingClassifier(random_state=42, max_leaf_nodes=4)),\n",
    "])\n",
    "\n",
    "model\n",
    "param_distributions = {\n",
    "    'classifier__l2_regularization': loguniform(1e-6, 1e3),\n",
    "    'classifier__learning_rate': loguniform(0.001, 10),\n",
    "    'classifier__max_leaf_nodes': loguniform_int(2, 256),\n",
    "    'classifier__min_samples_leaf': loguniform_int(1, 100),\n",
    "    'classifier__max_bins': loguniform_int(2, 255),\n",
    "}\n",
    "\n",
    "model_random_search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_distributions, n_iter=10,\n",
    "    cv=5, verbose=1,\n",
    ")\n",
    "model_random_search.fit(data_train, target_train)\n",
    "accuracy = model_random_search.score(data_test, target_test)\n",
    "\n",
    "print(f\"The test accuracy score of the best model is \"\n",
    "      f\"{accuracy:.2f}\")\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"The best parameters are:\")\n",
    "pprint(model_random_search.best_params_)\n",
    "# get the parameter names\n",
    "column_results = [\n",
    "    f\"param_{name}\" for name in param_distributions.keys()]\n",
    "column_results += [\n",
    "    \"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n",
    "\n",
    "cv_results = pd.DataFrame(model_random_search.cv_results_)\n",
    "cv_results = cv_results[column_results].sort_values(\n",
    "    \"mean_test_score\", ascending=False)\n",
    "\n",
    "def shorten_param(param_name):\n",
    "    if \"__\" in param_name:\n",
    "        return param_name.rsplit(\"__\", 1)[1]\n",
    "    return param_name\n",
    "\n",
    "cv_results = cv_results.rename(shorten_param, axis=1)\n",
    "cv_results\n",
    "cv_results = pd.read_csv(\"../figures/randomized_search_results.csv\",\n",
    "                         index_col=0)\n",
    "\n",
    "(cv_results[column_results].rename(\n",
    "    shorten_param, axis=1).sort_values(\"mean_test_score\", ascending=False))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ipy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a6bedd3509665544335308e415059c0a09ae1dacea269d4d09537be5f92701a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
